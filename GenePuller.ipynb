{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a08a4add",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0254b7",
   "metadata": {},
   "source": [
    "### Set of python scripts for:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea3cc1",
   "metadata": {},
   "source": [
    "- downloading the assembled genomes corresponding to a set of jc #'s\n",
    "- blasting the assembled genomes against a set of specified blast databases for specific genes\n",
    "- finding the best match (or lack thereof) to each genome for each gene, extracting the gene from the genome and saving it in a separate fasta file\n",
    "- viewing the results of the blast searches (whether successful, and what the species of the best match was) in spreadsheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922391e3",
   "metadata": {},
   "source": [
    "### What you need to run this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c2c0a",
   "metadata": {},
   "source": [
    "- python3\n",
    "- biopython\n",
    "- rclone, with the shared Assembled_Genomes google drive configured as 'assembled_genomes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430fdfb",
   "metadata": {},
   "source": [
    "## Functions and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-liver",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-coast",
   "metadata": {},
   "source": [
    "#### Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pulls the JC number out of a file name or other string\n",
    "### Input: string\n",
    "### output: JC #\n",
    "def find_JC_number(mystring):\n",
    "    import re\n",
    "    try:\n",
    "        return(re.search('JC-[0-9]+[0-9]+[0-9]+[0-9]+', mystring).group(0))\n",
    "    except AttributeError:\n",
    "        return(None)\n",
    "\n",
    "\n",
    "### Pulls all the names of JC assemblies from the google drive via rclone into a list\n",
    "### Input: name of rclone directory\n",
    "### Output: list of all full paths to assembled genomes with \"JC-\" in the name\n",
    "def get_JC_fasta_file_names(rclone_dir_name):\n",
    "    import os\n",
    "    genome_string = os.popen(\"rclone ls --include '*JC-*.fasta' \"+rclone_dir_name+\":\").read()\n",
    "    genome_list = [i.strip().split(None, 1)[1] for i in genome_string.split('\\n') if i]\n",
    "    return(genome_list)\n",
    "\n",
    "### Get the full path of the corresponding genome assembly file on google drive from the JC number; \n",
    "### throw an error if there are no matches or more than one match\n",
    "### Input: JC#, list from 'get_JC_fasta_file_names'\n",
    "### Output: path to the assembled genome corresponding to the JC#\n",
    "def get_JC_fasta_path_from_JC_num(JC_num, genome_list):\n",
    "    matches=[]\n",
    "    for fasta_file_path in genome_list:\n",
    "        if JC_num in fasta_file_path:\n",
    "            matches.append(fasta_file_path)\n",
    "    if len(matches) == 1:\n",
    "        return(matches[0])\n",
    "    if len(matches) > 1:\n",
    "        raise ValueError(JC_num+\" has more than one match:\\n\"+\"\\n\".join(matches))\n",
    "    if len(matches) == 0:\n",
    "        raise ValueError(JC_num+\" has no matches in the genome list\")\n",
    "\n",
    "### Download an assembled genome from google drive/rclone using the full file path to the genome\n",
    "### optional: specify a directory in which to download the genomes; otherwise will download to pwd\n",
    "### Input: name of rclone directory, path to genome from 'get_JC_fasta_path_from_JC_num'\n",
    "### Output: downloaded genome\n",
    "def download_genome_from_drive(rclone_dir_name, path_to_genome, directory=\"\"):\n",
    "    from pathlib import Path\n",
    "    fasta_name = path_to_genome.split(\"/\")[-1]\n",
    "    if directory == \"\":\n",
    "        cp_dir=\"\"\n",
    "        fasta_location=fasta_name\n",
    "    else:\n",
    "        cp_dir=\"/\"+directory\n",
    "        fasta_location=cp_dir+\"/\"+fasta_name\n",
    "    if Path(fasta_location).is_file():\n",
    "        return(fasta_location)\n",
    "    else:\n",
    "        import os\n",
    "        rclone_copy_cmd = \"rclone copy \"+'\"'+rclone_dir_name+\":\"+path_to_genome+'\"'+\" .\"+cp_dir\n",
    "        #rclone_copy_cmd = \"rclone copy \"+'\"'+rclone_dir_name+\":\"+path_to_genome+'\"'+\" .\"\n",
    "        os.system(rclone_copy_cmd)\n",
    "        return(fasta_location)\n",
    "    \n",
    "### Combines multiple functions to download the assembled genomes corresponding to a JC #\n",
    "### Inputs: JC #, output from 'get_JC_fasta_file_names' (list of assembled genomes)\n",
    "### assumes the genomes you want are in 'assembled_genomes'\n",
    "### Output: downloaded genome\n",
    "def get_jc_fasta_all(JC_num, genome_list, directory=\"\",rclone_dir_name=\"assembled_genomes\"):\n",
    "    path_to_genome = get_JC_fasta_path_from_JC_num(JC_num, genome_list)\n",
    "    return(download_genome_from_drive(rclone_dir_name, path_to_genome, directory))\n",
    "\n",
    "### Checks if a fasta file is already a blast database; otherwise makes in into a blast database\n",
    "### Inputs: path to the fasta file in question, and whether it contains nucleotide or protein seqs (\"nucl\" or \"prot\")\n",
    "### Note: currently just checks to see if ONE type of file extensino is present that hsoudl be for blast db\n",
    "### could improve this to include all types\n",
    "### Output: blast database or 'already a database' message\n",
    "def make_blast_db(fasta_file, filetype, makenew=False):\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    if filetype==\"prot\":\n",
    "        check = \".pdb\"\n",
    "    else:\n",
    "        check = \".ndb\"\n",
    "    if Path(fasta_file+check).is_file() and makenew==False:\n",
    "        print(fasta_file, \"already db\")\n",
    "        return(fasta_file)\n",
    "    else:\n",
    "        make_db_cmd = \"makeblastdb -in \"+fasta_file+\" -dbtype \"+filetype+\" -parse_seqids\"\n",
    "        print(make_db_cmd)\n",
    "        os.system(make_db_cmd) \n",
    "        return(fasta_file)\n",
    "    \n",
    "### Inputs: fasta file, blast db, blast db type (\"prot\" or \"nucl\"), evalue (defaults to 1e-4)\n",
    "### Output: printed results of the blast search\n",
    "### I don't remember why I made this but I had a good reason, I'm sure\n",
    "### ASSUMES NUCLEOTIDE QUERY\n",
    "def do_a_blast_and_print_results(fasta_query, database, database_type, evalue=1e-4):\n",
    "    if \"JC\" in fasta_query:\n",
    "        query_short_name = find_JC_number(fasta_query)\n",
    "    else:\n",
    "        query_short_name = fasta_query.rsplit(\".\",1)[0]\n",
    "    if database_type == \"prot\":\n",
    "        runtype = \"blastx\"\n",
    "    elif database_type == \"nucl\":\n",
    "        runtype = \"blastn\"\n",
    "    else:\n",
    "        print(\"no valid database type specified!\")\n",
    "    outname = \"temp.blast.out\"\n",
    "    blast_statement = runtype+\" -query \"+fasta_query+\" -db \"+database+\" -outfmt 6 -evalue \"+str(evalue)+\" -out \"+outname\n",
    "    #print(blast_statement)\n",
    "    os.system(blast_statement)\n",
    "    with open(\"temp.blast.out\", \"r\") as infile:\n",
    "        for line in infile:\n",
    "            print(line.strip())\n",
    "    os.system(\"rm \"+outname)\n",
    "\n",
    "### Inputs: fasta file, blast db, blast db type (\"prot\" or \"nucl\"), pretty database name, evalue (defaults to 1e-4)\n",
    "### Outputs: blast results to folder \n",
    "def do_a_blast_to_folder(fasta_query, database, database_name, database_type, folder, evalue=1e-4):\n",
    "    if \"JC\" in fasta_query:\n",
    "        query_short_name = find_JC_number(fasta_query)\n",
    "    else:\n",
    "        query_short_name = fasta_query.rsplit(\".\",1)[0]\n",
    "    if database_type == \"prot\":\n",
    "        runtype = \"blastx\"\n",
    "    elif database_type == \"nucl\":\n",
    "        runtype = \"blastn\"\n",
    "    else:\n",
    "        print(\"no valid database type specified!\")\n",
    "    outname = folder+\"/\"+query_short_name+\"_vs_\"+database_name+\".\"+runtype\n",
    "    blast_statement = runtype+\" -query \"+fasta_query+\" -db \"+database+\" -outfmt 6 -evalue \"+str(evalue)+\" -out \"+outname\n",
    "    #print(blast_statement)\n",
    "    os.system(blast_statement)\n",
    "\n",
    "### Pulls out a gene from a genome using the scaffold/contig name and the start and stop position\n",
    "### Inputs: fasta file with query genome, name of sequence with wanted gene, start and end indices of gene, \n",
    "### name for the new file to store the gene in\n",
    "### outputs: nucleotide snippet in new fasta file\n",
    "def pull_a_sequence(fasta_file, scaffold_name, start, end, newfilename):\n",
    "    from Bio import SeqIO\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    fragments_list = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        if record.id == scaffold_name:\n",
    "            frag = record.seq[start:end]\n",
    "            newrecord = SeqRecord(frag, record.id+\"[\"+str(start)+\":\"+str(end)+\"]\", \"\", \"\")\n",
    "            fragments_list.append(newrecord)\n",
    "    SeqIO.write(fragments_list, newfilename, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a directory if it doesn't already exist\n",
    "def new_dir(directory):\n",
    "    import os\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "### Combines many of the above functions to download the \n",
    "### assembled genomes corresponding to a list of jc #'s in a text file\n",
    "### Inputs: txt file with list of jc #s, place to download (default is a folder called 'jc_files')\n",
    "### Note: this will check the specified directory to see if any are already downloaded\n",
    "### Outputs: a directory full of the downloaded genomes that you want\n",
    "def download_jcs_from_list(file_of_jc_nums,download_directory=\"jc_files\", rclone_dir = \"assembled_genomes\"):\n",
    "    jc_dict = {}\n",
    "    new_dir(download_directory)\n",
    "    dict_of_already_downloaded_files = {find_JC_number(i):i for i in glob.glob(download_directory+\"/\"+\"*.fasta\")}\n",
    "    with open(file_of_jc_nums, \"r\") as infile:\n",
    "        for i in infile:\n",
    "            jc_num = i.strip()\n",
    "            if jc_num in dict_of_already_downloaded_files:\n",
    "                jc_dict[jc_num] = dict_of_already_downloaded_files[jc_num]\n",
    "            else:\n",
    "                jc_dict[jc_num] = get_jc_fasta_all(jc_num, genome_list, directory=download_directory,rclone_dir_name=rclone_dir)\n",
    "    return(jc_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70570f9f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preliminary steps for running blast searches (can do these steps without input JC #'s or query genomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f9b0f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get the list of assembled genomes in the google drive \"Assembled Genomes\" (this takes a little while to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-redhead",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "genome_list = get_JC_fasta_file_names(\"assembled_genomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-sixth",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setup:\n",
    "    - directory of dbs, with individual folder for each db that is labeled wtih a good name for that gene \n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-right",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get a spreadsheet showing you all the databases of genes you have, and which species are present in each (helpful when you are iteratively adding new sequences to your database and want to see which species don't have genes representing them in a particular database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144ae56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make it easier to specify whether you want to use the protein or nucleotide databases for fungi. Could add to this dictionary if we want to add other categories (Staph, bacteria, whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-detection",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db_dict = {\"fungus\":{\"nucl\":\"fungal_dbs_nucl\", \"prot\":\"fungal_dbs_prot\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ca76c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creates a dictionary of all the nucleotide and protein databases within the high-level db categories, to get a list of available genes that could be searched for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-calgary",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "quik_db = {}\n",
    "for i in db_dict:\n",
    "    quik_db[i] = {}\n",
    "    for j in db_dict[i]:\n",
    "        quik_db[i][j] = []\n",
    "for i in db_dict:\n",
    "    for j in db_dict[i]:\n",
    "        db_folder = db_dict[i][j]\n",
    "        for directory in glob.glob(db_folder+\"/*\"):\n",
    "            gene = directory.split(\"/\")[1]\n",
    "            quik_db[i][j].append(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a10fc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creates empty dictionary in which to save the species included in each dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-access",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dictionary_of_db_species  = {}\n",
    "for i in db_dict:\n",
    "    dictionary_of_db_species[i] = {}\n",
    "    for j in db_dict[i]:\n",
    "        dictionary_of_db_species[i][j] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782471a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Iterates through all the blast databases to find species present in each\n",
    "\n",
    "For databases of genes which contain that species, tag is \"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-brand",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for i in db_dict:\n",
    "    for j in db_dict[i]:\n",
    "        db_folder = db_dict[i][j]\n",
    "        gene_list = quik_db[i][j]\n",
    "        for directory in glob.glob(db_folder+\"/*\"):\n",
    "            gene = directory.split(\"/\")[1]\n",
    "            for file in glob.glob(directory+\"/*.fasta\"):\n",
    "                for record in SeqIO.parse(file, \"fasta\"):\n",
    "                    mrna = \"\"\n",
    "                    if j==\"nucl\":\n",
    "                        if re.search('mrna', record.description, re.IGNORECASE):\n",
    "                            mrna = \"_mRNA\"\n",
    "                        species = \" \".join(record.description.split(\" \")[1:3])\n",
    "                    if j==\"prot\":\n",
    "                        species = record.description.split(\"[\")[1].strip(\"]\")\n",
    "                    if species in dictionary_of_db_species[i][j]:\n",
    "                        dictionary_of_db_species[i][j][species][gene] = \"YES\"+mrna\n",
    "                    else:\n",
    "                        dictionary_of_db_species[i][j][species] = {i:\"\" for i in gene_list}\n",
    "                        dictionary_of_db_species[i][j][species][gene] = \"YES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c969f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creates new csv spreadsheet listing all the species in rows, and the blast databases (i.e. genes) in columns: presence/absence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-struggle",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for species_type in dictionary_of_db_species:\n",
    "    for blast_type in dictionary_of_db_species[species_type]:\n",
    "        header_list = quik_db[species_type][blast_type]\n",
    "        term = species_type+\"_\"+blast_type\n",
    "        outfile = open(term+\"_database.csv\", \"w\")\n",
    "        outfile.write(\",\"+\",\".join(header_list)+\"\\n\")\n",
    "        newlines = []\n",
    "        for species in dictionary_of_db_species[species_type][blast_type]:\n",
    "            info = [dictionary_of_db_species[species_type][blast_type][species][i] for i in header_list]\n",
    "            newline = species+\",\"+\",\".join(info)+\"\\n\"\n",
    "            newlines.append(newline)\n",
    "        newlines.sort()\n",
    "        for newline in newlines:\n",
    "            outfile.write(newline)\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-spare",
   "metadata": {},
   "source": [
    "## Inputs for the actual blast search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-crown",
   "metadata": {},
   "source": [
    "organism_type = fungus or bacteria\n",
    "\n",
    "blast_type = \"nucl\" or \"prot\" (are you using the nucleotide or protein database)\n",
    "\n",
    "update_blastdb = True or False <-- should the databases be remade (if you haven't added anything or otherwise touched them, this can be False)\n",
    "\n",
    "input_jc_list = name of txt file containing list of jc numbers to be blasted\n",
    "\n",
    "job_name = identifier which will be use to store results for the job (results will be in a directory under this name, so make it easy to identify, don't call it \"results\" or something)\n",
    "\n",
    "filter_factor = what percent length of the reference sequence should the query alignment match? .9 = 90%, for example. Best to start out with this number as a low value (<70%) and see what matches you get, then blast those matches against the NCBI database to see what new sequences to add to the database.\n",
    "\n",
    "NOTE: this script will automatically check for a directory called \"jc_files\", and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_type = \"fungus\"\n",
    "blast_type = \"nucl\"\n",
    "update_blastdb = True\n",
    "input_jc_list = \"test_file.txt\"\n",
    "job_name = \"fungal_gene_pull_test\"\n",
    "filter_factor = .9\n",
    "download_queries=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af9933",
   "metadata": {},
   "source": [
    "## Code for blasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-montreal",
   "metadata": {},
   "source": [
    "### Prepare places to store results from inputs\n",
    "- create new directory from job name\n",
    "- create blast results folder within new directory\n",
    "- get list of genes in fungal database\n",
    "- create directories for pulled genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new directory from job name\n",
    "new_dir(job_name)\n",
    "## Create blast results folder within new directory\n",
    "new_dir(job_name+\"/blast_results\")\n",
    "blast_results_dir = job_name+\"/blast_results\"\n",
    "## Get directory containing all the dbs used for this job based on fungus or bacteria\n",
    "db_to_use = db_dict[organism_type][blast_type]\n",
    "## from proper db directory, get list of genes (i.e. subfolders)\n",
    "genes = [directory.split(\"/\")[-1] for directory in glob.glob(db_to_use+\"/*\")]\n",
    "## Create empty dictionary for storing directory information for each gene\n",
    "gene_blasting_dict = {}\n",
    "gene_pulling_dict = {}\n",
    "for i in genes:\n",
    "    place_for_blast_results = blast_results_dir+\"/\"+i+\"_blast_results\"\n",
    "    place_for_pulled_gene = job_name+\"/\"+i+\"_pulled_gene\"\n",
    "    gene_blasting_dict[i] = place_for_blast_results\n",
    "    gene_pulling_dict[i] = place_for_pulled_gene\n",
    "    new_dir(place_for_blast_results)\n",
    "    new_dir(place_for_pulled_gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-marathon",
   "metadata": {},
   "source": [
    "### Make updated blast dbs (specify in inputs whether you want to update them or not, depending on whether you added new sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-badge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene_to_db_dict = {}\n",
    "for directory in glob.glob(db_to_use+\"/*\"):\n",
    "    for file in glob.glob(directory+\"/*.fasta\"):\n",
    "        gene_to_db_dict[directory.split(\"/\")[-1]] = make_blast_db(file, blast_type, makenew=update_blastdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea9ffd",
   "metadata": {},
   "source": [
    "### Create dictionary linking each database sequence id to the species it represents and its length. \n",
    "\n",
    "This will be used below to calculate the % length of an alignment to the reference sequence, as well as to build the results spreadsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_species_and_len = {}\n",
    "from Bio import SeqIO\n",
    "for gene in gene_to_db_dict:\n",
    "    gene_to_species_and_len[gene] = {}\n",
    "    for record in SeqIO.parse(gene_to_db_dict[gene], \"fasta\"):\n",
    "        if blast_type==\"nucl\":\n",
    "            species = \" \".join(record.description.split(\" \")[1:3])\n",
    "        if blast_type==\"prot\":\n",
    "            species = record.description.split(\"[\")[1].strip(\"]\")\n",
    "        gene_to_species_and_len[gene][record.id] = [species, len(record.seq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-channels",
   "metadata": {},
   "source": [
    "### Download needed jc files and save to dictionary (jc # : path to downloaded jc fasta file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_directory!=\"\":\n",
    "    new_dir(query_directory)\n",
    "jc_dict = download_jcs_from_list(input_jc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-spelling",
   "metadata": {},
   "source": [
    "### Actual blasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-battle",
   "metadata": {},
   "source": [
    "Iterate through each blast db that will be used for the job, and blast all the jc files against it. I built this for using on my laptop but for high-volume jobs on blastkid, should be able to assign each blast to its own core so that the jobs can be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-score",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for gene in gene_blasting_dict:\n",
    "    mydatabase = gene_to_db_dict[gene]\n",
    "    blast_results_folder = gene_blasting_dict[gene]\n",
    "    for jc_num in jc_dict:\n",
    "        query = jc_dict[jc_num].strip(\"/\")\n",
    "        do_a_blast_to_folder(fasta_query=query, database=mydatabase, database_name=gene, database_type=blast_type, folder=blast_results_folder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-document",
   "metadata": {},
   "source": [
    "### Parsing blast results to get best match for each jc file\n",
    "\n",
    "The meat of the matter: deciding which is the best blast hit for each gene and pulling out that gene, for each combination of query genome and gene database. This is pretty basic but it seems to perform well.\n",
    "\n",
    "This is not currently set up to detect multiple copies of the gene in a genome, just to find the best match.\n",
    "\n",
    "Steps are as follows:\n",
    "1. Iterates through each gene/blast database of interest (Example: calmodulin database)\n",
    "2. Then iterates through each blast result for that gene\n",
    "3. Returns \"NO MATCH\" if blast result file is empty\n",
    "4. Otherwise, iterates through each match in the blast result file, with an initial 'best % identity' of 0\n",
    "5. If a match doesn't meet the % requirement specified by 'filter_factor' in the inputs, it is skipped\n",
    "6. Otherwise the % identity of the match is compared with the previous % identity, and if the % identity is better, it is saved as the 'best % identity'\n",
    "7. Once all results from the blast results file have been compared, saves the best match to a dictionary\n",
    "8. If none of the results in the blast results file met the length requirement, returns \"NO MATCH MORE THAN (some % you specified) OF REF SEQ\" instead of the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-publication",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for gene in gene_blasting_dict:\n",
    "    results[gene] = {}\n",
    "    blast_saved_loc = gene_blasting_dict[gene]\n",
    "    gene_save_loc = gene_pulling_dict[gene]\n",
    "    for file in glob.glob(blast_saved_loc+\"/*.blast*\"):\n",
    "        jc_num = find_JC_number(file)\n",
    "        if os.stat(file).st_size == 0:\n",
    "            results[gene][jc_num] = [\"NO MATCH\"]\n",
    "        else:\n",
    "            query = jc_dict[jc_num].strip(\"/\")\n",
    "            newfilename = gene_save_loc+\"/\"+jc_num+\"_\"+gene+\".fasta\"\n",
    "            with open(file) as infile:\n",
    "                best_perc_ident = 0\n",
    "                best_db = \"no good match\"\n",
    "                for line in infile:\n",
    "                    cols = line.strip().split(\"\\t\")\n",
    "                    db_name = cols[1]\n",
    "                    perc_ident = cols[2]\n",
    "                    alignment_length = cols[3]\n",
    "                    ref_len_perc = float(gene_to_species_and_len[gene][db_name][1])*filter_factor\n",
    "                    if ref_len_perc < float(alignment_length):\n",
    "                        if float(perc_ident) > best_perc_ident:\n",
    "                            best_perc_ident = float(perc_ident)\n",
    "                            scaffold_name = cols[0]\n",
    "                            best_db = db_name\n",
    "                            qstart = int(cols[6])\n",
    "                            qend = int(cols[7])\n",
    "                            if qstart > qend:\n",
    "                                temp = qstart\n",
    "                                qstart = qend\n",
    "                                qend = temp\n",
    "                            match = [gene_to_species_and_len[gene][best_db][0], \n",
    "                                     perc_ident, scaffold_name, alignment_length, gene_to_species_and_len[gene][best_db][1],qstart, qend]\n",
    "                if best_db == \"no good match\":\n",
    "                    results[gene][jc_num] = [\"NO MATCH MORE THAN {}% OF REF SEQ\".format(int(filter_factor*100))]\n",
    "                else:\n",
    "                    results[gene][jc_num] = match\n",
    "                    pull_a_sequence(query, match[2], match[5], match[6], newfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-product",
   "metadata": {},
   "source": [
    "### Get ordered list of jc numbers of this job for saving results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_list_for_saving = list(jc_dict.keys())\n",
    "jc_list_for_saving.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-operation",
   "metadata": {},
   "source": [
    "### Write full results for each gene to file and collect info for writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-address",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gene_specific_header = \",\".join([\"JC_Number\",\"Best_Match_Species\",\"Percent_identity\",\"Scaffold\",\"Alignment_length\",\"Reference_seq_length\",\"Start\",\"End\"])+\"\\n\"\n",
    "general_results_header = [\"JC_Number\"]\n",
    "general_results = {i:[] for i in jc_list_for_saving}\n",
    "for gene in results:\n",
    "    outfilename = job_name+\"/\"+job_name+\"_\"+gene+\".csv\"\n",
    "    outfile = open(outfilename, \"w\")\n",
    "    outfile.write(gene_specific_header)\n",
    "    general_results_header = general_results_header + [gene+\"_best_match_species\", gene+\"_perc_identity\"]\n",
    "    for jc_num in jc_list_for_saving:\n",
    "        species = results[gene][jc_num][0]\n",
    "        if \"NO MATCH\" in species:\n",
    "            general_results[jc_num] = general_results[jc_num]+[species+\",\"]\n",
    "        else:\n",
    "            general_results[jc_num] = general_results[jc_num]+[species,str(results[gene][jc_num][1])]\n",
    "        newline = jc_num+\",\"+\",\".join([str(i) for i in results[gene][jc_num]])+\"\\n\"\n",
    "        outfile.write(newline)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-laugh",
   "metadata": {},
   "source": [
    "### Write general results for each gene to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-adapter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(job_name+\"/\"+job_name+\"_\"+\"results.csv\", \"w\") as outfile:\n",
    "    outfile.write(\",\".join(general_results_header)+\"\\n\")\n",
    "    for jc_num in jc_list_for_saving:\n",
    "        write_statement = jc_num+\",\"+\",\".join(general_results[jc_num])+\"\\n\"\n",
    "        outfile.write(write_statement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
